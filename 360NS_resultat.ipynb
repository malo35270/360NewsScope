{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE QUI DOIT FONCTIONNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display, HTML\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier = '../data/archive/result'\n",
    "hierarchical_topics = pd.read_csv(f\"{dossier}/database_hierarchical_topics.csv\",sep=',',encoding='utf8')\n",
    "news_data = pd.read_csv(f\"{dossier}/database_update.csv\",sep=',',encoding='utf8')\n",
    "all_topic = pd.read_csv(f\"{dossier}/all_topics.csv\",sep=',',encoding='utf8').iloc[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                               Name  \\\n",
      "0      0    741  0_obamacare_insurance_health_care   \n",
      "1      1    557   1_emails_server_email_classified   \n",
      "2      2    546    2_gun_guns_awrhawkins_amendment   \n",
      "3      3    458    3_campus_milo_students_berkeley   \n",
      "4      4    447    4_poll_percent_voters_electoral   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  ['obamacare', 'insurance', 'health', 'care', '...   \n",
      "1  ['emails', 'server', 'email', 'classified', 'f...   \n",
      "2  ['gun', 'guns', 'awrhawkins', 'amendment', 'ha...   \n",
      "3  ['campus', 'milo', 'students', 'berkeley', 'un...   \n",
      "4  ['poll', 'percent', 'voters', 'electoral', 'po...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  ['WASHINGTON — Vice Mike Pence top Republicans...  \n",
      "1  ['Following prepared text remarks Director Jam...  \n",
      "2  ['people armed , Donald J. Trump says rallies ...  \n",
      "3  ['BERKELEY , Calif. — Fires burned cradle free...  \n",
      "4  ['Washington ( CNN ) Democratic nominee Hillar...  \n"
     ]
    }
   ],
   "source": [
    "print(all_topic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", select_menu=True, layout=False)    \n",
    "news_net.barnes_hut()\n",
    "max_original_topic = hierarchical_topics.Parent_ID.astype(int).min() - 1\n",
    "\n",
    "        # Extract mapping from ID to name\n",
    "topic_to_name = dict(zip(hierarchical_topics.Child_Left_ID, hierarchical_topics.Child_Left_Name))\n",
    "topic_to_name.update(dict(zip(hierarchical_topics.Child_Right_ID, hierarchical_topics.Child_Right_Name)))\n",
    "topic_to_name.update(dict(zip(hierarchical_topics.Parent_ID, hierarchical_topics.Parent_Name)))\n",
    "\n",
    "topic_to_name = {topic: name for topic, name in topic_to_name.items()}\n",
    "#print((topic_to_name))\n",
    "        # Create tree\n",
    "tree = {row[1].Parent_ID: [row[1].Child_Left_ID, row[1].Child_Right_ID]\n",
    "        for row in hierarchical_topics.iterrows()}\n",
    "\n",
    "\n",
    "for parent,childs in tree.items():\n",
    "        src = parent\n",
    "        src_names = topic_to_name[parent]\n",
    "        lvl = hierarchical_topics.loc[hierarchical_topics['Parent_ID'] == parent, 'Distance'].values[0]\n",
    "        news_net.add_node(src, src_names, title=src,level=src)\n",
    "        for child in childs:\n",
    "                dst = child\n",
    "                dst_names = topic_to_name[child]\n",
    "                news_net.add_node(dst, dst_names, title=dst,level=dst)\n",
    "                news_net.add_edge(src, dst,values=lvl)\n",
    "        topic_str = hierarchical_topics.loc[hierarchical_topics['Parent_ID'] == parent, 'Topics'].values[0]\n",
    "        topics = set(int(topic.strip()) for topic in topic_str.strip('[]').split(','))\n",
    "        #print(f\"topics : {topics}\")\n",
    "        filter_child = topics - set(childs)\n",
    "        for child in filter_child:\n",
    "                childs_names = all_topic.loc[all_topic['Topic'] == child, 'Name'].values[0]\n",
    "                #print(child, childs_names)\n",
    "                news_net.add_node(child, str(childs_names), title=str(child))\n",
    "                news_net.add_edge(src, child,values=lvl)\n",
    "           \n",
    "\"\"\"\n",
    "for index, row in all_topic.iterrows():\n",
    "        list_doc = news_data.loc[news_data['topic'] == row['Topic'],'id', 'title',\"keyword\"].values\n",
    "        \n",
    "        for id,title,keywords in list_doc :\n",
    "                news_net.add_node(id,title,title=id)\n",
    "                news_net.add_edge(row['Topic'],id)\n",
    "                for keyword,distance in keywords :\n",
    "                        max = news_net.num_nodes()+1\n",
    "                        news_net.add_nodes(max,keyword,title=max)\n",
    "                        news_net.add_edge(id,max,distance)\n",
    "\"\"\"\n",
    "neighbor_map = news_net.get_adj_list()\n",
    "for node in news_net.nodes:\n",
    "# Assurez-vous que node[\"title\"] est une chaîne de caractères\n",
    "        node_title_str = node[\"label\"]\n",
    "        neighbors_str = \", \".join(str(neighbor) for neighbor in neighbor_map[node[\"id\"]])\n",
    "        # Utilisez la version chaîne de caractères de node[\"title\"] pour la concaténation\n",
    "        node[\"title\"] = node_title_str + \"\\n Neighbors : [\" + neighbors_str + \"]\"\n",
    "        node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "news_net.toggle_physics(True)\n",
    "news_net.show_buttons(True)\n",
    "news_net.inherit_edge_colors(True)\n",
    "news_net.save_graph(\"graphs_.html\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'archive/test/result/database_hierarchical_topics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m max_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      2\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m----> 3\u001b[0m hier_topics \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchive/test/result/database_hierarchical_topics.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_distance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     max_distance \u001b[38;5;241m=\u001b[39m hier_topics\u001b[38;5;241m.\u001b[39mDistance\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archive/test/result/database_hierarchical_topics.csv'"
     ]
    }
   ],
   "source": [
    "max_distance = None\n",
    "width = 1 \n",
    "hier_topics = pd.read_csv(f\"archive/test/result/database_hierarchical_topics.csv\")\n",
    "if max_distance is None:\n",
    "    max_distance = hier_topics.Distance.max() + 1\n",
    "\n",
    "max_original_topic = hier_topics.Parent_ID.astype(int).min() - 1\n",
    "\n",
    "# Extract mapping from ID to name\n",
    "topic_to_name = dict(zip(hier_topics.Child_Left_ID, hier_topics.Child_Left_Name))\n",
    "topic_to_name.update(dict(zip(hier_topics.Child_Right_ID, hier_topics.Child_Right_Name)))\n",
    "topic_to_name = {str(topic): name[:100] for topic, name in topic_to_name.items()}\n",
    "\n",
    "# Create tree\n",
    "tree = {str(row[1].Parent_ID): [str(row[1].Child_Left_ID), str(row[1].Child_Right_ID)]\n",
    "        for row in hier_topics.iterrows()}\n",
    "\n",
    "def get_tree(start, tree):\n",
    "    \"\"\" Based on: https://stackoverflow.com/a/51920869/10532563 \"\"\"\n",
    "\n",
    "    def _tree(to_print, start, parent, tree, grandpa=None, indent=\"\"):\n",
    "\n",
    "        # Get distance between merged topics\n",
    "        distance = hier_topics.loc[(hier_topics.Child_Left_ID == parent) |\n",
    "                                    (hier_topics.Child_Right_ID == parent), \"Distance\"]\n",
    "        distance = distance.values[0] if len(distance) > 0 else 10\n",
    "\n",
    "        if parent != start:\n",
    "            if grandpa is None:\n",
    "                to_print += topic_to_name[parent]\n",
    "            else:\n",
    "                if int(parent) <= max_original_topic:\n",
    "                    to_print += \"■──\" + topic_to_name[parent] + f\" ── Topic: {parent}\" + \"\\n\"\n",
    "                    \n",
    "                else:\n",
    "                    to_print += topic_to_name[parent] + \"\\n\"\n",
    "\n",
    "        if parent not in tree:\n",
    "            return to_print\n",
    "\n",
    "        for child in tree[parent][:-1]:\n",
    "            to_print += indent + \"├\" + \"─\"\n",
    "            to_print = _tree(to_print, start, child, tree, parent, indent + \"│\" + \" \" * width)\n",
    "\n",
    "        child = tree[parent][-1]\n",
    "        to_print += indent + \"└\" + \"─\"\n",
    "        to_print = _tree(to_print, start, child, tree, parent, indent + \" \" * (width+1))\n",
    "\n",
    "        return to_print\n",
    "\n",
    "    to_print = \".\" + \"\\n\"\n",
    "    to_print = _tree(to_print, start, start, tree)\n",
    "    return to_print\n",
    "\n",
    "start = str(hier_topics.Parent_ID.astype(int).max())\n",
    "print(get_tree(start, tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                              title  \\\n",
      "7170  25698.0  Without Obama, Shinzo Abe’s Approach to U.S.-J...   \n",
      "7171  25700.0  Giving Up ‘Mostly Everything’ to Care for His ...   \n",
      "7172  25701.0  Carrie Fisher, Trump, Israel: Your Wednesday E...   \n",
      "7173  25703.0  How to Have a Dinner Party: Friends Not Requir...   \n",
      "7174  25704.0                   The Fighter - The New York Times   \n",
      "7175  25705.0  A Brother’s Crimes and a Sister’s Betrayal Mak...   \n",
      "7176  25708.0  Uncertainty Over New Chinese Law Rattles Forei...   \n",
      "7177  25709.0  A Majority Agreed She Was Raped by a Stanford ...   \n",
      "7178  25710.0  Searching for the Human Factor in Deadly Avala...   \n",
      "7179  25713.0  Michael Skakel’s Murder Conviction Has Been Re...   \n",
      "\n",
      "         publication                             author        date    year  \\\n",
      "7170  New York Times                        Motoko Rich  2017-01-05  2017.0   \n",
      "7171  New York Times                          John Otis  2016-12-29  2016.0   \n",
      "7172  New York Times  Karen Zraick and Sandra Stevenson  2016-12-29  2016.0   \n",
      "7173  New York Times                    Hannah Seligson  2017-04-10  2017.0   \n",
      "7174  New York Times                      C. J. Chivers  2017-04-10  2017.0   \n",
      "7175  New York Times                        Nina Siegal  2017-04-13  2017.0   \n",
      "7176  New York Times                      Chris Buckley  2017-04-14  2017.0   \n",
      "7177  New York Times           Joe Drape and Marc Tracy  2017-04-12  2017.0   \n",
      "7178  New York Times                          Steph Yin  2017-01-24  2017.0   \n",
      "7179  New York Times      Alan Feuer and Kristin Hussey  2017-04-12  2017.0   \n",
      "\n",
      "      month  url                                            content  \n",
      "7170    1.0  NaN  TOKYO  —   Since becoming prime minister for t...  \n",
      "7171   12.0  NaN  “Don’t scratch it. ” Those were the first word...  \n",
      "7172   12.0  NaN  (Want to get this briefing by email? Here’s th...  \n",
      "7173    4.0  NaN  Over roast chicken and autumn vegetables, our ...  \n",
      "7174    4.0  NaN  Sam Siatta was deep in a tequila haze, so stag...  \n",
      "7175    4.0  NaN  AMSTERDAM  —   When he read the   sample of As...  \n",
      "7176    4.0  NaN  BEIJING  —   The hotline rings, but nobody ans...  \n",
      "7177    4.0  NaN  At Stanford University, in a conference room a...  \n",
      "7178    1.0  NaN  Every year, about 30 Americans die in avalanch...  \n",
      "7179    4.0  NaN  In the latest twist in a case that has been fu...  \n",
      "RangeIndex(start=7170, stop=7180, step=1)\n",
      "Key exists!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"../data/archive/database_merge.csv\")\n",
    "key_to_check = 7174\n",
    "print(df[7170:7180])\n",
    "print(df.index[7170:7180])\n",
    "if key_to_check in df.index:\n",
    "    # Proceed with operations on \n",
    "    print(\"Key exists!\")\n",
    "else:\n",
    "    print(\"Key does not exist in the DataFrame index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "g = Network()\n",
    "g.add_nodes([1,2,3], value=[10, 100, 400],\n",
    "                         title=['I am node 1', 'node 2 here', 'and im node 3'],\n",
    "                         x=[21.4, 54.2, 11.2],\n",
    "                         y=[100.2, 23.54, 32.1],\n",
    "                         label=['NODE 1', 'NODE 2', 'NODE 3'],\n",
    "                         color=['#00ff1e', '#162347', '#dd4b39'])\n",
    "g.add_node(1,\"test\")\n",
    "g.save_graph('nx.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
